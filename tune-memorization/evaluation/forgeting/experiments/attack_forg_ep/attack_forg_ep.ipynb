{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c60179b-af90-4764-b479-bc9303c60111",
   "metadata": {},
   "source": [
    "# Data extraction attack for forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc2c1f8-8478-4437-b0fe-89c545cc4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# parallel processing\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# utility§\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57e64f90-9113-4d81-a905-d7d1a52a2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805703c2-cd4d-4a57-a73e-e95ec0e10da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the metrics\n",
    "import evaluate\n",
    "exact_match_metric = evaluate.load(\"exact_match\")\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def bleu_compute(pred, suffix):\n",
    "    return sacrebleu.compute(predictions = pred, references = suffix)[\"score\"]\n",
    "\n",
    "def em_compute(pred, suffix):\n",
    "    return exact_match_metric.compute(references=pred, predictions=suffix)['exact_match']\n",
    "\n",
    "def meteor_compute(pred, suffix):\n",
    "    return meteor.compute(predictions = pred, references = suffix)[\"meteor\"]\n",
    "\n",
    "def rouge_compute(pred, suffix):\n",
    "    return rouge.compute(predictions = pred, references = suffix)[\"rougeL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c847eed-5549-4c94-9291-6ef96a4404ab",
   "metadata": {},
   "source": [
    "IMPORTANT TO CHANGE\n",
    "\n",
    "To change depending on the model you want to attack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "896bb31d-3463-4646-9dd7-e1c01b278af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bigcode/starcoder2-3b\"\n",
    "# checkpoint = \"bigcode/starcoder2-7b\"\n",
    "# checkpoint = \"bigcode/starcoder2-15b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca2514f-cf8a-4b33-b996-93390320191a",
   "metadata": {},
   "source": [
    "# Load the sample for the attack (g3 mem) and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915aa42-c640-4429-95a0-116763d2fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('mem-tune-replication_package/mem-tune/data/samples/pre-train/forget-attack/pre-train_attack_g3.parquet')\n",
    "df = Dataset.from_pandas(df[['prefix_250', 'prefix_200', 'prefix_150', 'prefix_100', 'suffix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936826a-bbe2-4357-8e45-67694c96983c",
   "metadata": {},
   "source": [
    "Parameters for this experiment:\n",
    "\n",
    "- deduplication rate >3\n",
    "- prefix length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "580964eb-2153-4cf0-b4f4-acf6b4c4d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_length = 'prefix_100'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad04a0-6e10-4210-88fc-08cb26804f92",
   "metadata": {},
   "source": [
    "Setup the column names:\n",
    "\n",
    "- the generation is 7b_ep1, 7b_ep2, 7b_ep3\n",
    "\n",
    "- for the metric we are just adding the _metric-name to 7b_ep3_bleu, 7b_ep3_meteor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "212b4983-dfb7-4d08-b545-b5ba1ec82c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the experiment names\n",
    "\n",
    "m_name = checkpoint.split('-')[1] # take only the nymber of parameters\n",
    "\n",
    "epochs = ['_ep0', '_ep1', '_ep2', '_ep3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3b7bf-6f4e-4af6-ae9a-760191920f96",
   "metadata": {},
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "508c7064-da19-4eb8-8ef3-dc4b3ec67192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c6e7e",
   "metadata": {},
   "source": [
    "**IMPORTANT**\n",
    "\n",
    "In the public replication package we will also share the fine-tuned models on Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "739daa97-6a82-4786-82ef-bd26a87d0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dirs\n",
    "#To change depending on which model you want to attack!\n",
    "\n",
    "ep_dir = '/model_dir/scoder3b/epochs'\n",
    "ep1 = ep_dir +'/checkpoint-833'\n",
    "ep2 = ep_dir + '/checkpoint-1666'\n",
    "ep3= ep_dir + '/checkpoint-2499'\n",
    "\n",
    "# ep_dir = '/model_dir/scoder7b/epochs'\n",
    "# ep1 = ep_dir +'/checkpoint-833'\n",
    "# ep2 = ep_dir + '/checkpoint-1666'\n",
    "# ep3= ep_dir + '/checkpoint-2499'\n",
    "\n",
    "# ep_dir = '/model_dir/scoder15b/epochs'\n",
    "# ep1 = ep_dir +'/checkpoint-800'\n",
    "# ep2 = ep_dir + '/checkpoint-1600'\n",
    "# ep3= ep_dir + '/checkpoint-2400'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3481db-15d2-43a5-97f6-8d77e65ad0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "#To change depending on which model you want to attack!\n",
    "\n",
    "# base model\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,device_map=\"auto\")\n",
    "epoch = epochs[0]\n",
    "\n",
    "# model depending on the epoch\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep1,device_map=\"auto\")\n",
    "# epoch = epochs[1]\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep2,device_map=\"auto\")\n",
    "# epoch = epochs[2]\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep3,device_map=\"auto\")\n",
    "# epoch = epochs[3]\n",
    "\n",
    "# eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96ba00c2-9fc8-46c8-98cf-e9b3401e0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the pipeline\n",
    "pipe = pipeline(\"text-generation\", model = model, tokenizer = tokenizer, framework='pt', max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd49ce63-ea45-4d94-88f4-304f0934f43c",
   "metadata": {},
   "source": [
    "IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ef1fd-d7d6-4a23-9397-f37ee6547c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "\n",
    "gen_name = m_name + epoch\n",
    "print(gen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb3ec4-9b5f-4081-af6e-f0f28a79ed53",
   "metadata": {},
   "source": [
    "# Now we can generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "497a2682-6ec4-451d-8e4e-c414fb7c38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_mem = pipe(df[p_length], batch_size=32)\n",
    "\n",
    "# for forgetting\n",
    "df = df.add_column(gen_name, [gs_mem[i][0]['generated_text'][len(df[p_length][i]):]  for i,_ in enumerate(df)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ee8cdd-ffd2-4dd3-ab84-408124d1e4b0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172864a-ef17-4b34-ab4b-3d731e3e768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name + '_em'\n",
    "bleu = gen_name + '_bleu'\n",
    "met = gen_name + '_meteor'\n",
    "roug = gen_name + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a445014-a72c-45a5-9eaf-2f53e57ecae3",
   "metadata": {},
   "source": [
    "First of all we need to load the eval dataframe and then attach the new generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de534126-5f0d-4981-9e63-bac2c51b521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial attack\n",
    "df_eval= df.to_pandas()\n",
    "\n",
    "# After is saved the first time\n",
    "# df_eval = pd.merge((pd.read_parquet('mem-tune/evaluation/forgeting/experiments/attack_forg_ep/attack_forg_ep.parquet')), df.to_pandas()[gen_name], left_index =True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c90ea-e917-4d9e-baf6-ad8af03655f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval[em] = df_eval.progress_apply(lambda x: em_compute( pred= [x[gen_name]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[bleu] = df_eval.progress_apply(lambda x: bleu_compute( pred= [x[gen_name]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[met] = df_eval.progress_apply(lambda x: meteor_compute( pred= [x[gen_name]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[roug] = df_eval.progress_apply(lambda x: rouge_compute( pred= [x[gen_name]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c5e541e-c808-47cc-8874-5a982d63eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "df_eval.to_parquet('mem-tune/evaluation/forgeting/experiments/attack_forg_ep/attack_forg_ep.parquet', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

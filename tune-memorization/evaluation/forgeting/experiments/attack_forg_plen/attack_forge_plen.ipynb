{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a7a04-18dd-48d4-a74a-25194fcbf8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# parallel processing\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0030f44-2c4e-4d2a-a322-e5b358561184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34775992-1d21-4cae-9e75-a7bf399eafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the metrics\n",
    "import evaluate\n",
    "exact_match_metric = evaluate.load(\"exact_match\")\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def bleu_compute(pred, suffix):\n",
    "    return sacrebleu.compute(predictions = pred, references = suffix)[\"score\"]\n",
    "\n",
    "def em_compute(pred, suffix):\n",
    "    return exact_match_metric.compute(references=pred, predictions=suffix)['exact_match']\n",
    "\n",
    "def meteor_compute(pred, suffix):\n",
    "    return meteor.compute(predictions = pred, references = suffix)[\"meteor\"]\n",
    "\n",
    "def rouge_compute(pred, suffix):\n",
    "    return rouge.compute(predictions = pred, references = suffix)[\"rougeL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f02c8",
   "metadata": {},
   "source": [
    "To change depending on which model you want to attack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3461971-ecd7-49b4-a6a3-9d8059e2b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bigcode/starcoder2-3b\"\n",
    "# checkpoint = \"bigcode/starcoder2-7b\"\n",
    "# checkpoint = \"bigcode/starcoder2-15b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1c3dd-3c3d-4788-a6f8-4225fd6d47c1",
   "metadata": {},
   "source": [
    "# Load the sample datasets for the mem attacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c0d38b-2b5b-40e0-adc2-8fa3403798cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('mem-tune-replication_package/mem-tune/data/samples/pre-train/forget-attack/pre-train_attack_g3.parquet')\n",
    "df = Dataset.from_pandas(df[['prefix_250', 'prefix_200', 'prefix_150', 'prefix_100', 'suffix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189df0ce-d119-4655-89ca-d6ea187f5a1b",
   "metadata": {},
   "source": [
    "Parameters for this experiment:\n",
    "\n",
    "- epochs 3\n",
    "- deduplication rate >3\n",
    "- we have 4 setups of prefix-length 100, 150, 200, 250\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199a1128-2288-43bd-a3d3-57368b488a35",
   "metadata": {},
   "source": [
    "Setup the column names:\n",
    "\n",
    "- the generation is 7b_ep0_p100, 7b_ep0_p150, 7b_ep3_p250\n",
    "\n",
    "- for the metric we are just adding the _metric-name to 7b_ep3_p100_bleu, 7b_p150_ep3_meteor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c358417f-94be-4a6d-a04c-f736184da65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the experiment names\n",
    "\n",
    "m_name = checkpoint.split('-')[1] # take only the nymber of parameters\n",
    "\n",
    "epochs = ['_ep0', '_ep1', '_ep2', '_ep3']\n",
    "\n",
    "plen = ['_p100', '_p150','_p200','_p250']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c709f-35f7-4ab5-bebe-6bad49e0c065",
   "metadata": {},
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82ceb1d-0068-403e-bbf2-34eab84ab68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be07fb",
   "metadata": {},
   "source": [
    "**IMPORTANT**\n",
    "\n",
    "In the public replication package we will also share the fine-tuned models on Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34e0b643-e39e-43a5-bbcd-4c5b1c82cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dirs\n",
    "#To change depending on which model you want to attack!\n",
    "\n",
    "ep_dir = '/model_dir/scoder3b/epochs'\n",
    "ep1 = ep_dir +'/checkpoint-833'\n",
    "ep2 = ep_dir + '/checkpoint-1666'\n",
    "ep3= ep_dir + '/checkpoint-2499'\n",
    "\n",
    "# ep_dir = '/model_dir/scoder7b/epochs'\n",
    "# ep1 = ep_dir +'/checkpoint-833'\n",
    "# ep2 = ep_dir + '/checkpoint-1666'\n",
    "#Â ep3= ep_dir + '/checkpoint-2499'\n",
    "\n",
    "# ep_dir = '/model_dir/scoder15b/epochs'\n",
    "# ep1 = ep_dir +'/checkpoint-800'\n",
    "# ep2 = ep_dir + '/checkpoint-1600'\n",
    "# ep3= ep_dir + '/checkpoint-2400'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14cc92b-c3ba-43d5-99ab-549bd72227d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "#To change depending on which model you want to attack!\n",
    "\n",
    "# base model\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,device_map=\"auto\")\n",
    "epoch = epochs[0]\n",
    "\n",
    "# model depending on the epoch\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep1,device_map=\"auto\")\n",
    "# epoch = epochs[1]\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep2,device_map=\"auto\")\n",
    "# epoch = epochs[2]\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep3,device_map=\"auto\")\n",
    "# epoch = epochs[3]\n",
    "\n",
    "# eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a688006-2615-41d1-861d-0893fa51d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the pipeline\n",
    "pipe = pipeline(\"text-generation\", model = model, tokenizer = tokenizer, framework='pt', max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a01d7c-cf80-4d28-83c4-8d52d42576e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "\n",
    "gen_name_100 = m_name + epoch + plen[0]\n",
    "gen_name_150 = m_name + epoch + plen[1]\n",
    "gen_name_200 = m_name + epoch + plen[2]\n",
    "gen_name_250 = m_name + epoch + plen[3]\n",
    "\n",
    "print(f\"{gen_name_100}\\n {gen_name_150}\\n {gen_name_200}\\n {gen_name_250}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea560f-71cc-4db3-be79-b9c247155910",
   "metadata": {},
   "source": [
    "# Now we can generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7209e8-0d51-4515-9037-01dec537542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_mem_100 = pipe(df['prefix_100'], batch_size=32)\n",
    "print('100 done')\n",
    "gs_mem_150 = pipe(df['prefix_150'], batch_size=32)\n",
    "print('150 done')\n",
    "gs_mem_200 = pipe(df['prefix_200'], batch_size=32)\n",
    "print('200 done')\n",
    "gs_mem_250 = pipe(df['prefix_250'], batch_size=32)\n",
    "print('250 done')\n",
    "\n",
    "# Save the results on each of the datasets\n",
    "df = df.add_column(gen_name_100, [gs_mem_100[i][0]['generated_text'][len(df['prefix_100'][i]):]  for i,_ in enumerate(df)])\n",
    "df = df.add_column(gen_name_150, [gs_mem_150[i][0]['generated_text'][len(df['prefix_150'][i]):]  for i,_ in enumerate(df)])\n",
    "df = df.add_column(gen_name_200, [gs_mem_200[i][0]['generated_text'][len(df['prefix_200'][i]):]  for i,_ in enumerate(df)])\n",
    "df = df.add_column(gen_name_250, [gs_mem_250[i][0]['generated_text'][len(df['prefix_250'][i]):]  for i,_ in enumerate(df)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef53a5-6aa8-4d1f-9782-9706c633610c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c55f3138-684f-4abb-941c-b4cfa5112221",
   "metadata": {},
   "outputs": [],
   "source": [
    "expath = 'mem-tune-replication_package/mem-tune/evaluation/forgeting/experiments/attack_forg_plen/attack_forg_plen.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "409977e4-1394-4ea6-8f66-d16309065158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial attack\n",
    "df_eval= df.to_pandas()\n",
    "\n",
    "# After is saved the first time\n",
    "df_eval = pd.merge((pd.read_parquet(expath + '/attack_forg_plen.parquet')), df.to_pandas()[[gen_name_100, gen_name_150, gen_name_200, gen_name_250]], left_index =True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19808e7-962a-4675-81a1-2e5ae325bbf1",
   "metadata": {},
   "source": [
    "plen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad5a05-6907-4b8c-82ff-d8db4cae7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name_100 + '_em'\n",
    "bleu = gen_name_100 + '_bleu'\n",
    "met = gen_name_100 + '_meteor'\n",
    "roug = gen_name_100 + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9af3b2-b8f7-4ac6-93a6-a4bb8083352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval[em] = df_eval.progress_apply(lambda x: em_compute( pred= [x[gen_name_100]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[bleu] = df_eval.progress_apply(lambda x: bleu_compute( pred= [x[gen_name_100]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[met] = df_eval.progress_apply(lambda x: meteor_compute( pred= [x[gen_name_100]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[roug] = df_eval.progress_apply(lambda x: rouge_compute( pred= [x[gen_name_100]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f007385-9a20-4377-be1d-986d6bad5840",
   "metadata": {},
   "source": [
    "plen = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6446625-5e61-471c-9671-63cf712d1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name_150 + '_em'\n",
    "bleu = gen_name_150 + '_bleu'\n",
    "met = gen_name_150 + '_meteor'\n",
    "roug = gen_name_150 + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c958fa3-738e-4475-b8c2-ad5e324a6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval[em] = df_eval.progress_apply(lambda x: em_compute( pred= [x[gen_name_150]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[bleu] = df_eval.progress_apply(lambda x: bleu_compute( pred= [x[gen_name_150]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[met] = df_eval.progress_apply(lambda x: meteor_compute( pred= [x[gen_name_150]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[roug] = df_eval.progress_apply(lambda x: rouge_compute( pred= [x[gen_name_150]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502241eb-1800-4101-b113-719429ff8921",
   "metadata": {},
   "source": [
    "plen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1812fc62-d452-44c7-9d81-1f66ce5f40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name_200 + '_em'\n",
    "bleu = gen_name_200 + '_bleu'\n",
    "met = gen_name_200 + '_meteor'\n",
    "roug = gen_name_200 + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d16c92-b4d3-449d-a7cb-4990c0eaf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval[em] = df_eval.progress_apply(lambda x: em_compute( pred= [x[gen_name_200]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[bleu] = df_eval.progress_apply(lambda x: bleu_compute( pred= [x[gen_name_200]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[met] = df_eval.progress_apply(lambda x: meteor_compute( pred= [x[gen_name_200]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[roug] = df_eval.progress_apply(lambda x: rouge_compute( pred= [x[gen_name_200]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434628f7-fa03-4f8d-965e-8c8a837debe1",
   "metadata": {},
   "source": [
    "plen = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67767dcb-b12a-4dab-baac-98df2e3478ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name_250 + '_em'\n",
    "bleu = gen_name_250 + '_bleu'\n",
    "met = gen_name_250 + '_meteor'\n",
    "roug = gen_name_250 + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56fddd-0d5b-42de-b6c0-ef31449dccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval[em] = df_eval.progress_apply(lambda x: em_compute( pred= [x[gen_name_250]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[bleu] = df_eval.progress_apply(lambda x: bleu_compute( pred= [x[gen_name_250]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[met] = df_eval.progress_apply(lambda x: meteor_compute( pred= [x[gen_name_250]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval[roug] = df_eval.progress_apply(lambda x: rouge_compute( pred= [x[gen_name_250]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21bdb6cf-c086-41ec-b292-64e98d0ab5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "df_eval.to_parquet(os.path.join(expath, 'attack_forg_plen.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

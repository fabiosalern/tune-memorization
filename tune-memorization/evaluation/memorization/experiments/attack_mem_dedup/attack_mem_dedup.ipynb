{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415369cc-8a5a-41d9-8a84-9866d8f19026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# parallel processing\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fd69b-7847-4f14-8fa0-30017319e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the metrics\n",
    "import evaluate\n",
    "exact_match_metric = evaluate.load(\"exact_match\")\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def bleu_compute(pred, suffix):\n",
    "    return sacrebleu.compute(predictions = pred, references = suffix)[\"score\"]\n",
    "\n",
    "def em_compute(pred, suffix):\n",
    "    return exact_match_metric.compute(references=pred, predictions=suffix)['exact_match']\n",
    "\n",
    "def meteor_compute(pred, suffix):\n",
    "    return meteor.compute(predictions = pred, references = suffix)[\"meteor\"]\n",
    "\n",
    "def rouge_compute(pred, suffix):\n",
    "    return rouge.compute(predictions = pred, references = suffix)[\"rougeL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a485466-c49c-4903-bd44-da02d31194cc",
   "metadata": {},
   "source": [
    "To change depending on which model you want to attack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e14a87-5ee9-4d3e-823d-e5dd5c0554a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bigcode/starcoder2-3b\"\n",
    "# checkpoint = \"bigcode/starcoder2-7b\"\n",
    "# checkpoint = \"bigcode/starcoder2-15b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced2707-28f5-4281-ae8e-d0e2fef511ef",
   "metadata": {},
   "source": [
    "# Load the sample datasets for the mem attacks (different deduplication rates)\n",
    "\n",
    "- = 1 (df_1)\n",
    "- = 2 (df_2)\n",
    "- = 3 (df_3)\n",
    "- \\> 3 (df_g3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29796f5e-98e6-4e39-9a85-8848f9f388d2",
   "metadata": {},
   "source": [
    "Deduplication rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f197d73-cc38-40c3-a544-a239842e4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_parquet('mem-tune-replication_package/mem-tune/data/samples/fine-tune/mem-attack/fine-tune_attack_1.parquet')\n",
    "df_1 = Dataset.from_pandas(df_1[['prefix_250', 'prefix_200', 'prefix_150', 'prefix_100', 'suffix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ebe5d7-75fa-483c-b773-739f04ef2c01",
   "metadata": {},
   "source": [
    "Deduplication rate = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e4aec-6b65-48d3-8b4b-c2312b3e26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_parquet('mem-tune-replication_package/mem-tune/data/samples/fine-tune/mem-attack/fine-tune_attack_2.parquet')\n",
    "df_2 = Dataset.from_pandas(df_2[['prefix_250', 'prefix_200', 'prefix_150', 'prefix_100', 'suffix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e8bb9-3a81-41ba-bc25-b923a3ef7500",
   "metadata": {},
   "source": [
    "Deduplication rate = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc26adb-539a-4d11-8ba9-3c8891db9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_parquet('mem-tune-replication_package/mem-tune/data/samples/fine-tune/mem-attack/fine-tune_attack_3.parquet')\n",
    "df_3 = Dataset.from_pandas(df_3[['prefix_250', 'prefix_200', 'prefix_150', 'prefix_100', 'suffix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c524f-182a-49c0-a205-8bf3da2f9872",
   "metadata": {},
   "source": [
    "Deduplication rate > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340688a-10b4-4b89-a17f-3cff33b6e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g3 = pd.read_parquet('mem-tune-replication_package/mem-tune/data/samples/fine-tune/mem-attack/fine-tune_attack_g3.parquet')\n",
    "df_g3 = Dataset.from_pandas(df_g3[['prefix_250', 'prefix_200', 'prefix_150', 'prefix_100', 'suffix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5009b58a-3ad9-4dd9-a5cb-4b161a6f2323",
   "metadata": {},
   "source": [
    "Parameters for this experiment:\n",
    "- training epochs fixed to 3\n",
    "- prefix length fixed to 100 tokens\n",
    "- We are gonna vay the deduplication rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb47946-a824-42c0-b270-6428a2caf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_length = 'prefix_100'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3273cfb9-8442-4862-9aad-17aa45b775d3",
   "metadata": {},
   "source": [
    "Setup the column names:\n",
    "- The generation will be the same 7b_ep0_d1, 7b__ep3_d2, 7b_ep_0_d3, 7b_ep3_dg3 (the epochs are fixed to three now so we don't need to keep track of that, but we will need to have also the baseline value ep_0)\n",
    "- For the metrics we are gonna add the _metric, i.e. 7b_ep3_d3_bleu, 7b_ep3_d3_meteor, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af9a4003-587e-4d9d-909e-545781c508cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the experiment names\n",
    "\n",
    "m_name = checkpoint.split('-')[1] # take only the nymber of parameters\n",
    "\n",
    "epochs = ['_ep0', '_ep1', '_ep2', '_ep3']\n",
    "\n",
    "deduplication = ['_d1', '_d2','_d3','_dg3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24518926-609b-4d70-be31-9770d18c0a35",
   "metadata": {},
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0df5f871-4411-4aa8-8598-3502dbef39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a7a0d-5509-46f0-85f7-33c259020055",
   "metadata": {},
   "source": [
    "**IMPORTANT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7777d8",
   "metadata": {},
   "source": [
    "In the public replication package we will also share the fine-tuned models on Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9eab99-758c-4bab-8093-8c248aea9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dirs\n",
    "#To change depending on which model you want to attack!\n",
    "\n",
    "# ep_dir = '/model_dir/scoder3b/epochs'\n",
    "# ep1 = ep_dir +'/checkpoint-833'\n",
    "# ep2 = ep_dir + '/checkpoint-1666'\n",
    "# ep3= ep_dir + '/checkpoint-2499'\n",
    "\n",
    "# ep_dir = '/model_dir/scoder7b/epochs'\n",
    "# ep1 = ep_dir +'/checkpoint-833'\n",
    "# ep2 = ep_dir + '/checkpoint-1666'\n",
    "#Â ep3= ep_dir + '/checkpoint-2499'\n",
    "\n",
    "ep_dir = '/model_dir/scoder15b/epochs'\n",
    "ep1 = ep_dir +'/checkpoint-800'\n",
    "ep2 = ep_dir + '/checkpoint-1600'\n",
    "ep3= ep_dir + '/checkpoint-2400'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fdb89e-ca0a-4ba7-a74b-5a33fee30bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "# base model\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,device_map=\"auto\")\n",
    "epoch = epochs[0]\n",
    "\n",
    "# model depending on the epoch\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep1,device_map=\"auto\")\n",
    "# epoch = epochs[1]\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep2,device_map=\"auto\")\n",
    "# epoch = epochs[2]\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(ep3,device_map=\"auto\")\n",
    "# epoch = epochs[3]\n",
    "\n",
    "# eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb41259-afe6-46aa-b2dc-fc46dbcc08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the pipeline\n",
    "pipe = pipeline(\"text-generation\", model = model, tokenizer = tokenizer, framework='pt', max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab551f-187a-427f-91de-63d66f1ce19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "\n",
    "gen_name_1 = m_name + epoch + deduplication[0]\n",
    "gen_name_2 = m_name + epoch + deduplication[1]\n",
    "gen_name_3 = m_name + epoch + deduplication[2]\n",
    "gen_name_g3 = m_name + epoch + deduplication[3]\n",
    "\n",
    "print(f\"{gen_name_1}\\n {gen_name_2}\\n {gen_name_3}\\n {gen_name_g3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745c524-30b7-429e-8308-93344f61377c",
   "metadata": {},
   "source": [
    "# Now we can generate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba942228-8e89-4e6b-bd52-d06a200bcd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_mem_1 = pipe(df_1[p_length], batch_size=32)\n",
    "print('1 done')\n",
    "gs_mem_2 = pipe(df_2[p_length], batch_size=32)\n",
    "print('2 done')\n",
    "gs_mem_3 = pipe(df_3[p_length], batch_size=32)\n",
    "print('3 done')\n",
    "gs_mem_g3 = pipe(df_g3[p_length], batch_size=32)\n",
    "print('g3 done')\n",
    "\n",
    "# Save the results on each of the datasets\n",
    "df_1 = df_1.add_column(gen_name_1, [gs_mem_1[i][0]['generated_text'][len(df_1[p_length][i]):]  for i,_ in enumerate(df_1)])\n",
    "df_2 = df_2.add_column(gen_name_2, [gs_mem_2[i][0]['generated_text'][len(df_2[p_length][i]):]  for i,_ in enumerate(df_2)])\n",
    "df_3 = df_3.add_column(gen_name_3, [gs_mem_3[i][0]['generated_text'][len(df_3[p_length][i]):]  for i,_ in enumerate(df_3)])\n",
    "df_g3 = df_g3.add_column(gen_name_g3, [gs_mem_g3[i][0]['generated_text'][len(df_g3[p_length][i]):]  for i,_ in enumerate(df_g3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52405f8e-7ecc-4367-a04c-7c5f0016ec5a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d0cbb8-948e-4189-bda6-ca85dcf05193",
   "metadata": {},
   "outputs": [],
   "source": [
    "expath = 'mem-tune/evaluation/memorization/experiments/attack_mem_dedup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98fc8a49-8762-4939-b387-6828d23a8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial save\n",
    "df_eval_1= df_1.to_pandas()\n",
    "df_eval_2= df_2.to_pandas()\n",
    "df_eval_3= df_3.to_pandas()\n",
    "df_eval_g3= df_g3.to_pandas()\n",
    "\n",
    "# After is saved the first time\n",
    "# df_eval_1 = pd.merge((pd.read_parquet(expath + '/attack_mem_dedup_1.parquet')), df_1.to_pandas()[gen_name_1], left_index =True, right_index=True)\n",
    "# df_eval_2 = pd.merge((pd.read_parquet(expath + '/attack_mem_dedup_2.parquet')), df_2.to_pandas()[gen_name_2], left_index =True, right_index=True)\n",
    "# df_eval_3 = pd.merge((pd.read_parquet(expath + '/attack_mem_dedup_3.parquet')), df_3.to_pandas()[gen_name_3], left_index =True, right_index=True)\n",
    "# df_eval_g3 = pd.merge((pd.read_parquet(expath + '/attack_mem_dedup_g3.parquet')), df_g3.to_pandas()[gen_name_g3], left_index =True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621a5f7-c8ba-4ec2-b2cd-20e681188709",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name_1 + '_em'\n",
    "bleu = gen_name_1 + '_bleu'\n",
    "met = gen_name_1 + '_meteor'\n",
    "roug = gen_name_1 + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd7c9b-1a05-4f04-a6a6-b9c72286cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval_1[em] = df_eval_1.progress_apply(lambda x: em_compute( pred= [x[gen_name_1]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_1[bleu] = df_eval_1.progress_apply(lambda x: bleu_compute( pred= [x[gen_name_1]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_1[met] = df_eval_1.progress_apply(lambda x: meteor_compute( pred= [x[gen_name_1]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_1[roug] = df_eval_1.progress_apply(lambda x: rouge_compute( pred= [x[gen_name_1]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf7236-debe-4f97-b1c3-0df7c2f13591",
   "metadata": {},
   "source": [
    "Deduplicaiton rate = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252e58e-aff0-4cff-a500-3fa99b5bc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name_2 + '_em'\n",
    "bleu = gen_name_2 + '_bleu'\n",
    "met = gen_name_2 + '_meteor'\n",
    "roug = gen_name_2 + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5093f9c4-588b-4ed3-b85a-e819d7a3b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval_2[em] = df_eval_2.progress_apply(lambda x: em_compute( pred= [x[gen_name_2]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_2[bleu] = df_eval_2.progress_apply(lambda x: bleu_compute( pred= [x[gen_name_2]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_2[met] = df_eval_2.progress_apply(lambda x: meteor_compute( pred= [x[gen_name_2]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_2[roug] = df_eval_2.progress_apply(lambda x: rouge_compute( pred= [x[gen_name_2]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42391892-d118-4bea-8299-bf4070ebed86",
   "metadata": {},
   "source": [
    "Deduplication rate = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b68df2-4f7f-4283-b519-203069c1fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name_3 + '_em'\n",
    "bleu = gen_name_3 + '_bleu'\n",
    "met = gen_name_3 + '_meteor'\n",
    "roug = gen_name_3 + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c34b8-48ec-454f-91c9-020b277e9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval_3[em] = df_eval_3.progress_apply(lambda x: em_compute( pred= [x[gen_name_3]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_3[bleu] = df_eval_3.progress_apply(lambda x: bleu_compute( pred= [x[gen_name_3]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_3[met] = df_eval_3.progress_apply(lambda x: meteor_compute( pred= [x[gen_name_3]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_3[roug] = df_eval_3.progress_apply(lambda x: rouge_compute( pred= [x[gen_name_3]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484f844-0b93-4dc2-89cf-a099e1627049",
   "metadata": {},
   "source": [
    "Deduplication rate > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb629eed-7764-4013-a419-56117a515f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = gen_name_g3 + '_em'\n",
    "bleu = gen_name_g3 + '_bleu'\n",
    "met = gen_name_g3 + '_meteor'\n",
    "roug = gen_name_g3 + '_rougeL'\n",
    "\n",
    "print(f\"{em}\\n {bleu}\\n {met}\\n {roug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2325659-16e7-4572-b326-c83f8594f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "df_eval_g3[em] = df_eval_g3.progress_apply(lambda x: em_compute( pred= [x[gen_name_g3]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_g3[bleu] = df_eval_g3.progress_apply(lambda x: bleu_compute( pred= [x[gen_name_g3]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_g3[met] = df_eval_g3.progress_apply(lambda x: meteor_compute( pred= [x[gen_name_g3]], suffix = [x['suffix']]), axis=1)\n",
    "df_eval_g3[roug] = df_eval_g3.progress_apply(lambda x: rouge_compute( pred= [x[gen_name_g3]], suffix = [x['suffix']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88c7f0-de78-45a2-817e-dae1758d5483",
   "metadata": {},
   "source": [
    "# Save all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "392cd71b-a5dd-430b-8436-90d8cfd542eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "expath = 'mem-tune/evaluation/memorization/experiments/attack_mem_dedup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14f68640-ac38-4f7f-ad0b-1d0ac062adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_1.to_parquet(os.path.join(expath, 'attack_mem_dedup_1.parquet'))\n",
    "df_eval_2.to_parquet(os.path.join(expath, 'attack_mem_dedup_2.parquet'))\n",
    "df_eval_3.to_parquet(os.path.join(expath, 'attack_mem_dedup_3.parquet'))\n",
    "df_eval_g3.to_parquet(os.path.join(expath, 'attack_mem_dedup_g3.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
